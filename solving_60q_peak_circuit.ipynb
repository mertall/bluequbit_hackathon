{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2251ed4-65f6-4128-875d-b4ca2f9ed2c6",
   "metadata": {},
   "source": [
    "# ðŸ§  Lightweight solution to a 'Peak' Quantum Circuit with Tensor Networks\n",
    "\n",
    "This notebook was developed during a quantum hackathon hosted by BlueQubit, a Series A startup focused on making quantum computing accessible across various platforms. Their toolset allows for a unified development environment, abstracting hardware and simulators so teams can focus on circuit logic.\n",
    "\n",
    "Our objective here is to simulate a 60-qubit quantum circuit where one dominant bitstring occurs with O(1) probability, while all others are exponentially less likely. We use tensor networks to do this efficiently, with help from:\n",
    "\n",
    "- `Quimb`: constructs and simulates quantum circuits as tensor networks.\n",
    "- `Cotengra`: finds optimal contraction paths for the tensor network.\n",
    "- A majority vote mechanism to identify the most likely bitstring through sampling.\n",
    "\n",
    "Throughout this notebook, I explore technical decisions and implementation challenges, and reflect on why certain methods worked better than expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb1a75d",
   "metadata": {},
   "source": [
    "# ðŸ“¦ Import Required Libraries\n",
    "\n",
    "Weâ€™ll use the following tools:\n",
    "\n",
    "- `quimb.tensor` to define the circuit and convert it into a tensor network.\n",
    "- `cotengra` to optimize the contraction path, which becomes critical at scale.\n",
    "- `numpy`, `collections.defaultdict` for general data handling.\n",
    "- `multiprocessing` and `time` to help with runtime tracking and performance tuning.\n",
    "\n",
    "Each of these plays a role in making large quantum simulations practical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02fa653e-ab69-4d8a-b960-b87b9a1f3376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import quimb.tensor as qtn\n",
    "import numpy as np\n",
    "import cotengra as ctg\n",
    "from collections import defaultdict\n",
    "from multiprocessing import freeze_support\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd9988d",
   "metadata": {},
   "source": [
    "### â±ï¸ Format Timing Output\n",
    "\n",
    "This utility function makes runtime output more human-readable. Itâ€™s a minor touch, but helpful for tracking performance at different stages of simulation and optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb70c9ad-9250-454a-8fd9-742146b0d4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(seconds):\n",
    "    \"\"\"Return a formatted string for a time duration in minutes and seconds if > 60 sec, otherwise in seconds.\"\"\"\n",
    "    if seconds < 60:\n",
    "        return f\"{seconds:.2f} seconds\"\n",
    "    else:\n",
    "        minutes = int(seconds // 60)\n",
    "        rem_seconds = seconds % 60\n",
    "        return f\"{minutes} minutes {rem_seconds:.2f} seconds\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bffe15",
   "metadata": {},
   "source": [
    "### ðŸ—³ï¸ Determine Dominant Bitstring via Majority Vote\n",
    "\n",
    "The function `compute_majority_vote` aggregates sampled bitstrings to extract the most frequent bit at each position.\n",
    "\n",
    "> Initially, I was skeptical about this working reliably. But reframing the hidden bitstring as a strong signal amidst weak noise led me to this majority vote logic. Itâ€™s simple. We treat each position independently and aggregate statistics across many samples.\n",
    "> You will need to add some guardrails if looking for string without knowing its value. Either inserting a value as a tie breaker, or not allowing tie breakers to take place and pushing to next iteration to see if it resolves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "331bd771-4386-42ce-9fbc-8d2bf53ffaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_majority_vote(bit_counts, num_qubits):\n",
    "    \"\"\"Return the majority vote bitstring from current per-position counts.\"\"\"\n",
    "    final_bits = []\n",
    "    for i in range(num_qubits):\n",
    "        count_0 = bit_counts[i].get('0', 0)\n",
    "        count_1 = bit_counts[i].get('1', 0)\n",
    "        # In case of a tie, choose '1'\n",
    "        final_bits.append('1' if count_1 > count_0 else '0')\n",
    "    return ''.join(final_bits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c94605",
   "metadata": {},
   "source": [
    "### âŒ› Begin Benchmarking\n",
    "\n",
    "We use this timing block to measure the total wall-clock time for our full workflowâ€”from circuit loading to final sampling and bitstring extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89632f16-17e7-4f0d-b0db-e57e2d142378",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_start = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53164b69",
   "metadata": {},
   "source": [
    "### ðŸ§  Load the 60-Qubit Circuit\n",
    "\n",
    "Here, we initialize the 60-qubit circuit and load it from an OpenQASM file into a tensor network using Quimb.\n",
    "\n",
    "> You'll likely encounter some warnings from Quimbâ€™s QASM parser. These can be safely ignored in this case, as they donâ€™t affect the resulting tensor network structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "facda4e2-acee-4f9c-93a9-3870263357be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading circuit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mridul.sarkar/Documents/BlueQubitHackathon/venv/lib/python3.9/site-packages/quimb/tensor/circuit.py:221: SyntaxWarning: Unsupported operation ignored: creg\n",
      "  warnings.warn(\n",
      "/Users/mridul.sarkar/Documents/BlueQubitHackathon/venv/lib/python3.9/site-packages/quimb/tensor/circuit.py:221: SyntaxWarning: Unsupported operation ignored: measure\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circuit loaded.\n",
      "\n",
      "Loading circuit took 0.83 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Setup: Initialize the circuit with 60 qubits and load the QASM file.\n",
    "circ = qtn.Circuit(N=60)\n",
    "print(\"Loading circuit...\")\n",
    "load_start = time.perf_counter()\n",
    "tensor_network_circuit = circ.from_openqasm2_file(\n",
    "    './circuit_3_60q.qasm'\n",
    ")\n",
    "load_end = time.perf_counter()\n",
    "print(\"Circuit loaded.\\n\")\n",
    "print(f\"Loading circuit took {format_time(load_end - load_start)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc186bdf",
   "metadata": {},
   "source": [
    "### ðŸ§® Set Up Cotengra Contraction Optimizer\n",
    "\n",
    "We configure Cotengra's optimizer to find efficient paths for contracting the tensor network.\n",
    "\n",
    "> This step was surprisingly insightful. I compared different optimizers (`nevergrad`, `cmaes`, `random`) but found `optuna` worked the best. I need to study these optimizer a bit more to study trade off. It takes a while to run so will need to leverage GPUs for that work to make it go faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2df6db83-836d-47d5-9b07-ab7f7994f911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up contraction optimizer...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Setup the contraction optimizer using cotengra.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetting up contraction optimizer...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m opt_start \u001b[38;5;241m=\u001b[39m \u001b[43mtime\u001b[49m\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m      4\u001b[0m opt \u001b[38;5;241m=\u001b[39m ctg\u001b[38;5;241m.\u001b[39mReusableHyperOptimizer(\n\u001b[1;32m      5\u001b[0m     parallel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m     optlib\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptuna\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     progbar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m opt_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "# Setup the contraction optimizer using cotengra.\n",
    "print(\"Setting up contraction optimizer...\")\n",
    "opt_start = time.perf_counter()\n",
    "opt = ctg.ReusableHyperOptimizer(\n",
    "    parallel=True,\n",
    "    optlib=\"optuna\",\n",
    "    max_time=\"rate:1e8\",  # Limit optimization time.\n",
    "    directory=True,\n",
    "    progbar=True,\n",
    ")\n",
    "opt_end = time.perf_counter()\n",
    "print(\"Done setting up contraction optimizer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ef3c50",
   "metadata": {},
   "source": [
    "### ðŸ” Optimize Sampling Strategy\n",
    "\n",
    "We rehearse contraction paths for all marginal distributions weâ€™ll need during sampling. This makes actual sampling much faster later on.\n",
    "\n",
    "> This step felt like prepping a lookup table for all future measurements. Quimbâ€™s design makes it very intuitive to offload this complexity while still having fine-grained control. Definitely something to carry forward when designing future tensor-based simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfdbf5b-a5a6-4833-b287-21c869870ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rehearse the sampling path (pre-optimizes contraction paths for each marginal).\n",
    "print(\"Optimizing contraction path...\")\n",
    "path_opt_start = time.perf_counter()\n",
    "rehs = tensor_network_circuit.sample_gate_by_gate_rehearse(\n",
    "    group_size=10,\n",
    "    optimize=opt,\n",
    "    simplify_sequence=\"ADCRS\"  # Using \"ADCRS\" for simplification.\n",
    ")\n",
    "path_opt_end = time.perf_counter()\n",
    "print(f\"Contraction path optimization took {format_time(path_opt_end - path_opt_start)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0188e88a",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Define Target Bitstring\n",
    "\n",
    "This bitstring is expected to dominate the probability distribution after circuit execution. Including it allows us to verify our majority vote or compare results from simulation to theoretical expectations.\n",
    "\n",
    "> Optional, but handy for debugging and benchmarking against known expected outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862246c0-a943-4fa1-8d92-d9fbb5e78cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target bitstring and number of qubits.\n",
    "target_bitstring = \"110101001011010101111001011100001110101101111010100110110001\"\n",
    "num_qubits = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd543503",
   "metadata": {},
   "source": [
    "### ðŸ“ Sample and Log Output Bitstrings\n",
    "\n",
    "Here we perform the actual sampling from the optimized tensor network. Each sample gives us one possible outcome of the circuit measurement. We stream all results to a file for further analysis.  What makes this implementation lightweight a combination of everything we did before, setting `sample_batch_size` to 1, and off loading calculation to determine the strongest bitstring signal. Together all the steps within this system were selected with computational constraint in mind.\n",
    "\n",
    "> This is the culmination of everything we set upâ€”from QASM parsing to optimizer rehearsal. If you're following the logic of tensor contraction and marginalization, this step shows how it all ties together. The process is repeatable and can be scaled to other circuits with similar structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305202ce-8d6f-4245-ba67-14aa0db5ae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare to continuously sample and save each bitstring to a file.\n",
    "output_file = \"./tensor_networks/samples.txt\"\n",
    "with open(output_file, \"a\") as f:\n",
    "    print(\"Starting continuous sampling and appending to file...\")\n",
    "    sample_loop_start = time.perf_counter()\n",
    "    # Maintain position-wise counts for majority vote.\n",
    "    position_counts = [defaultdict(int) for _ in range(num_qubits)]\n",
    "    rng = np.random.default_rng(42)\n",
    "    sample_batch_size = 1  # One sample per batch.\n",
    "    sample_count = 0\n",
    "\n",
    "    # Continuous sampling loop.\n",
    "    while True:\n",
    "        sample_iter_start = time.perf_counter()\n",
    "        # Generate one sample.\n",
    "        for b in tensor_network_circuit.sample_gate_by_gate(\n",
    "            sample_batch_size,\n",
    "            group_size=5,\n",
    "            optimize=opt,\n",
    "            simplify_sequence=\"ADCRS\",\n",
    "            seed=rng\n",
    "        ):\n",
    "            sample_iter_end = time.perf_counter()\n",
    "            sample_time = sample_iter_end - sample_iter_start\n",
    "            sample_count += 1\n",
    "            print(f\"Sample {sample_count}: {b} (took {format_time(sample_time)})\")\n",
    "            \n",
    "            # Write sample to file.\n",
    "            f.write(b + \"\\n\")\n",
    "            f.flush()  # Ensure persistence in case of interruption.\n",
    "            \n",
    "            # Update per-qubit counts.\n",
    "            for i, bit in enumerate(b):\n",
    "                position_counts[i][bit] += 1\n",
    "            \n",
    "            # Check current majority vote.\n",
    "            current_vote = compute_majority_vote(position_counts, num_qubits)\n",
    "            if current_vote == target_bitstring:\n",
    "                solution_time = time.perf_counter() - sample_loop_start\n",
    "                print(f\"\\nTarget bitstring achieved after {sample_count} samples in {format_time(solution_time)}.\")\n",
    "\n",
    "            # Reset timer for next sample.\n",
    "            sample_iter_start = time.perf_counter()\n",
    "            \n",
    "        # Log total sampling time every 10 samples.\n",
    "        if sample_count % 10 == 0:\n",
    "            current_time = time.perf_counter()\n",
    "            elapsed = current_time - sample_loop_start\n",
    "            print(f\"Processed {sample_count} samples in {format_time(elapsed)}.\")\n",
    "\n",
    "overall_end = time.perf_counter()\n",
    "print(f\"Overall process took {format_time(overall_end - overall_start)}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
